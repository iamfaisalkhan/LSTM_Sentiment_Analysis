{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "GLOVE_DIR = os.path.join(DATA_DIR, 'glove.6B')\n",
    "MAX_SEQUENCE_LENGTH = 15\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 200\n",
    "VALIDATION_SPLIT = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []  # list of text samples\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for name in ['yelp_labelled.txt', 'imdb_labelled.txt', 'amazon_cells_labelled.txt']:\n",
    "    path = os.path.join(DATA_DIR, name)\n",
    "    with open(path) as f:\n",
    "        text = f.read()\n",
    "        texts.extend([d.split('\\t')[0] for d in [d for d in text.split('\\n')] if len(d) > 0])\n",
    "        labels.extend([int(d.split('\\t')[1]) for d in [d for d in text.split('\\n')] if len(d) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.array(texts)\n",
    "labels = np.array(labels).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Text cleaning and stop words removal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/faisal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE, '', text)\n",
    "    return WhitespaceTokenizer().tokenize(text)\n",
    "\n",
    "tkns = list(map(text_prepare, texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for tkn in tkns:\n",
    "    counts.append(len(tkn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sequence length  11.796333333333333\n"
     ]
    }
   ],
   "source": [
    "print (\"Average sequence length \", sum(counts)/len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(counts, 30)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = [' '.join(tkn) for tkn in tkns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5374 unique tokens.\n",
      "Shape of data tensor: (3000, 15)\n",
      "Shape of label tensor: (3000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/keras/preprocessing/text.py:157: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(cleaned_text)\n",
    "sequences = tokenizer.texts_to_sequences(cleaned_text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "clabels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "clabels = clabels[indices]\n",
    "\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "X_train = data[:-num_validation_samples]\n",
    "Y_train = clabels[:-num_validation_samples]\n",
    "# Non-hot-encoded labels for sklearn GridSearchCV because it does the hot encoding internally. \n",
    "Y_train_orig = labels[:-num_validation_samples]\n",
    "X_val = data[-num_validation_samples:]\n",
    "Y_val = clabels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  Positive (+ve) examples in training (1195,).\n",
      "          Negative examples in training (1205,).\n",
      "          Positive examples in validation (305,).\n",
      "          Negative examples in validation (295,).\n"
     ]
    }
   ],
   "source": [
    "print (f\"\\t  Positive (+ve) examples in training {Y_train[:, 1].nonzero()[0].shape}.\\n \\\n",
    "         Negative examples in training {Y_train[:, 0].nonzero()[0].shape}.\\n \\\n",
    "         Positive examples in validation {Y_val[:, 1].nonzero()[0].shape}.\\n \\\n",
    "         Negative examples in validation {Y_val[:, 0].nonzero()[0].shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = np.random.choice(Y_train[:, 0].nonzero()[0], 500)\n",
    "pos_samples = np.random.choice(Y_train[:, 1].nonzero()[0], 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train[np.concatenate((neg_samples, pos_samples))]\n",
    "Y_train_small = Y_train_orig[np.concatenate((neg_samples, pos_samples))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-existing word embedding the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.200d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our word integer index as look-up in the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.2 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 64 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.2 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 256 dropout 0.5 recurrent_dropout 0.5 optimizer adam\n",
      "Building model with lstm_units 128 dropout 0.2 recurrent_dropout 0.5 optimizer rmsprop\n",
      "Parameters of the best model: \n",
      "{'batch_size': 32, 'dropout': 0.2, 'epochs': 30, 'lstm_units': 128, 'optimizer': 'rmsprop', 'recurrent_dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def build_model(lstm_units=128,\n",
    "                dropout=0.5,\n",
    "                recurrent_dropout=0.2,\n",
    "                optimizer='rmsprop'):\n",
    "    \n",
    "    print (f\"Building model with lstm_units {lstm_units} dropout {dropout} recurrent_dropout {recurrent_dropout} optimizer {optimizer}\")\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    X = SpatialDropout1D(0.4)(embedded_sequences)\n",
    "    X = LSTM(lstm_units, dropout=dropout, recurrent_dropout=0.2)(X)\n",
    "    X = Dense(2, activation='softmax')(X)\n",
    "\n",
    "    model = Model(sequence_input, X)\n",
    "    \n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model = KerasClassifier(build_fn=build_model,\n",
    "                        epochs=10, \n",
    "                        batch_size=5,\n",
    "                        verbose=0)\n",
    "\n",
    "param_grid = {'lstm_units': [64, 128, 256],\n",
    "              'dropout' : [0.2,  0.5],\n",
    "              'recurrent_dropout' : [0.2, 0.5],\n",
    "              'optimizer':('rmsprop','adam'),\n",
    "              'epochs':[10, 30],\n",
    "              'batch_size':[32, 64]}\n",
    "\n",
    "grid = GridSearchCV(model,\n",
    "                    param_grid=param_grid,\n",
    "                    return_train_score=True,\n",
    "                    scoring=['precision_macro','recall_macro','f1_macro'],\n",
    "                    refit='precision_macro')\n",
    "\n",
    "grid_results = grid.fit(X_train_small, Y_train_small)\n",
    "\n",
    "print('Parameters of the best model: ')\n",
    "print(grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
